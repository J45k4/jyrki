use anyhow::bail;
use reqwest::Client;
use reqwest::StatusCode;
use serde::Deserialize;
use serde::Serialize;
use serde_json::Value;
use crate::llm;
use crate::tool;

#[derive(Deserialize, Debug)]
struct ChatCompletion {
    id: String,
    object: String,
    created: i64,
    model: String,
    choices: Vec<Choice>,
    usage: Usage,
    system_fingerprint: String,
    service_tier: Option<String>,
}

impl ChatCompletion {
	fn to_successfull_gen_response(&self, model: &llm::Model) -> anyhow::Result<llm::SuccessfullGenResponse> {
		let first_choice = self.choices.first().ok_or_else(|| anyhow::anyhow!("no choices"))?;

		let res = llm::SuccessfullGenResponse {
			promt_cost: model.input_cost(self.usage.prompt_tokens),
			completion_cost: model.output_cost(self.usage.completion_tokens),
			msg: llm::AssistantMsg {
				content: first_choice.message.content.clone().unwrap_or_else(|| "".to_string()),
				tool_calls: match &first_choice.message.tool_calls {
					Some(tool_calls) => tool_calls.iter().filter_map(|tool_call| {
						// match Tool::parse(&tool_call.function.name, &tool_call.function.arguments) {
						// 	Ok(tool) => Some(llm::ToolCall {
						// 		id: tool_call.id.clone(),
						// 		tool,
						// 	}),
						// 	Err(_) => None
						// }

						Some(llm::ToolCall {
							id: tool_call.id.clone(),
							tool: Tool::parse(&tool_call.function.name, &tool_call.function.arguments).unwrap(),
						})
					}).collect(),
					None => vec![],
				},
			},
			prompt_tokens: self.usage.prompt_tokens,
			completion_tokens: self.usage.completion_tokens,
			total_tokens: self.usage.total_tokens,
		};

		Ok(res)
	}
}

#[derive(Deserialize, Debug)]
struct Choice {
    index: u32,
    message: OAIMessage,
    logprobs: Option<Logprobs>,
    finish_reason: String,
}

#[derive(Serialize, Deserialize, Debug)]
struct OAIMessage {
    role: String,
    content: Option<String>,
	tool_calls: Option<Vec<ToolCall>>,
    refusal: Option<String>,
	tool_call_id: Option<String>,
}

#[derive(Deserialize, Serialize, Debug)]
struct ToolCall {
    id: String,
    #[serde(rename = "type")]
    type_: String,  // `type` is a reserved keyword in Rust, so we use `type_` instead
    function: Function,
}

#[derive(Deserialize, Serialize, Debug)]
struct Function {
    name: String,
    arguments: String,  // Arguments in JSON format as generated by the model
}

impl Function {
	pub fn from_tool(tool: &tool::Tool) -> Function {
		match tool {
			tool::Tool::WriteFile(w) => Function {
				name: "write_file".to_string(),
				arguments: serde_json::to_string(w).unwrap(),
			},
			tool::Tool::ReadFile(r) => Function {
				name: "read_file".to_string(),
				arguments: serde_json::to_string(r).unwrap(),
			},
			tool::Tool::ListFolderContents(l) => Function {
				name: "list_folder_contents".to_string(),
				arguments: serde_json::to_string(l).unwrap(),
			},
			tool::Tool::CreateTodoItem(c) => Function {
				name: "create_folder".to_string(),
				arguments: serde_json::to_string(c).unwrap(),
			},
			tool::Tool::CompleteTodoItem(c) => Function {
				name: "delete_folder".to_string(),
				arguments: serde_json::to_string(c).unwrap(),
			},
			tool::Tool::FindText(f) => Function {
				name: "find_text".to_string(),
				arguments: serde_json::to_string(f).unwrap(),
			},
			tool::Tool::RemoveFile(r) => Function {
				name: "remove_file".to_string(),
				arguments: serde_json::to_string(r).unwrap(),
			},
		}
	}
}

#[derive(Deserialize, Debug)]
struct FunctionCall {
    name: String,
    arguments: String,
}

#[derive(Deserialize, Debug)]
struct Logprobs {
    content: Option<Vec<LogprobContent>>,
    refusal: Option<Vec<LogprobRefusal>>,
}

#[derive(Deserialize, Debug)]
struct LogprobContent {
    // Define fields for log probability of message content tokens
}

#[derive(Deserialize, Debug)]
struct LogprobRefusal {
    // Define fields for log probability of refusal tokens
}

#[derive(Deserialize, Debug)]
struct Usage {
    prompt_tokens: u32,
    completion_tokens: u32,
    total_tokens: u32,
}

#[derive(Serialize, Debug)]
struct OAIRequest {
	messages: Vec<OAIMessage>,
	model: String,
	tools: Vec<Value>
}

pub async fn gen(req: llm::GenRequest, client: Client) -> anyhow::Result<llm::SuccessfullGenResponse> {
	let oaireq = OAIRequest {
		model: req.model.to_str().to_string(),
		tools: req.tools.iter().map(|p| p.to_value()).collect(),
		messages: req.messages.iter().map(|msg| {
			match msg {
				llm::LLMMessage::Assistant(msg) => OAIMessage {
					role: "assistant".to_string(),
					content: Some(msg.content.clone()),
					tool_calls: if msg.tool_calls.len() > 0 {
						Some(msg.tool_calls.iter().map(|tool_call| {
							tool_call.
							ToolCall {
								id: tool_call.id.clone(),
								type_: "function".to_string(),
								function: Function::from_tool(&tool_call.tool),
							}
						}).collect())
					} else {
						None
					},
					refusal: None,
					tool_call_id: None,
				},
				llm::LLMMessage::User(msg) => OAIMessage {
					role: "user".to_string(),
					content: Some(msg.clone()),
					tool_calls: None,
					refusal: None,
					tool_call_id: None,
				},
				llm::LLMMessage::System(msg) => OAIMessage {
					role: "system".to_string(),
					content: Some(msg.clone()),
					tool_calls: None,
					refusal: None,
					tool_call_id: None,
				},
				llm::LLMMessage::ToolResponse(r) => OAIMessage {
					role: "tool".to_string(),
					content: Some(r.content.clone()),
					tool_calls: None,
					refusal: None,
					tool_call_id: Some(r.id.clone()),
				},
			}
		}).collect(),
	};

	let body = serde_json::to_string(&oaireq)?;
    let apikey = match std::env::var("OPENAI_API_KEY") {
		Ok(key) => key,
		Err(_) => {
			bail!("OPENAI_API_KEY not set");
		}
	};

	log::info!("body: {}", body);

    let res = client
        .post("https://api.openai.com/v1/chat/completions")
        .header("Authorization", format!("Bearer {}", apikey))
        .header("Content-Type", "application/json")
        .body(body)
        .send()
        .await?;

    let status_code = res.status();
	let text = res.text().await?;

	if status_code != StatusCode::OK {
		log::error!("request failed with code {}", status_code);
		log::error!("response: {}", text);
		bail!("request failed with code {}", status_code);
	}

	log::info!("response: {}", text);
    let chat_completion: ChatCompletion = serde_json::from_str(&text)?;
	let res = chat_completion.to_successfull_gen_response(&req.model)?;
    Ok(res)
}

#[cfg(test)]
mod tests {
	use super::*;

	#[test]
	fn test_parse_toolcall() {
		let str = r#"{
		"id": "asdfghasdfasdg",
		"object": "chat.completion",
		"created": 12412412,
		"model": "gpt-4o-mini-2024-07-18",
		"choices": [
			{
			"index": 0,
			"message": {
				"role": "assistant",
				"content": null,
				"tool_calls": [
					{
						"id": "asdgasdgagds",
						"type": "function",
						"function": {
							"name": "write_file",
							"arguments": "{\"content\":\"print('Hello, World!')\",\"linenumber\":0,\"path\":\"hello_world.py\"}"
						}
					}
				],
				"refusal": null
			},
			"logprobs": null,
			"finish_reason": "tool_calls"
			}
		],
		"usage": {
			"prompt_tokens": 380,
			"completion_tokens": 31,
			"total_tokens": 411
		},
		"system_fingerprint": "bvnmvnbm"
		}"#;

		let res = serde_json::from_str::<ChatCompletion>(str).unwrap();
		println!("{:?}", res);

		let result = res.to_successfull_gen_response(&llm::Model::GPT4OMini).unwrap();

		println!("{:?}", result);
	}
}